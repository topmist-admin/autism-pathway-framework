{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autism Pathway Framework - Demo Notebook\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/topmist-admin/autism-pathway-framework/blob/main/examples/notebooks/01_demo_end_to_end.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## RESEARCH USE ONLY\n",
    "\n",
    "> **This framework is for research and hypothesis generation purposes only.**\n",
    "> \n",
    "> - Outputs must NOT be used for clinical diagnosis, treatment decisions, or medical advice\n",
    "> - All findings require independent experimental and clinical validation\n",
    "> - See [DISCLAIMER.md](https://github.com/topmist-admin/autism-pathway-framework/blob/main/DISCLAIMER.md) for full details\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates the **Autism Pathway Framework** end-to-end pipeline:\n",
    "\n",
    "1. **Setup** - Install dependencies and clone repository\n",
    "2. **Load Data** - VCF variants, phenotypes, and pathway definitions\n",
    "3. **Compute Gene Burdens** - Aggregate variant impacts per gene\n",
    "4. **Compute Pathway Scores** - Aggregate gene burdens to biological pathways\n",
    "5. **Cluster Samples** - Identify molecular subtypes using GMM\n",
    "6. **Validate Results** - Run negative controls and stability tests\n",
    "7. **Interpret Outputs** - Understand what the results mean\n",
    "\n",
    "**Expected runtime:** 5-10 minutes on Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "First, we'll clone the repository and install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Google Colab\")\n",
    "    # Clone the repository\n",
    "    !git clone https://github.com/topmist-admin/autism-pathway-framework.git\n",
    "    %cd autism-pathway-framework\n",
    "    \n",
    "    # Install dependencies\n",
    "    !pip install -q -r requirements.txt\n",
    "    !pip install -q -e .\n",
    "else:\n",
    "    print(\"Running locally\")\n",
    "    # Assume we're already in the project directory\n",
    "    import os\n",
    "    # Navigate to project root if in notebooks folder\n",
    "    if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "        os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(\"All dependencies loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Load Data\n",
    "\n",
    "The demo dataset contains **synthetic data** with planted biological subtypes:\n",
    "\n",
    "- **50 samples** with simulated ASD diagnoses\n",
    "- **20 variants** across **18 genes**\n",
    "- **15 pathways** (synaptic, chromatin, ion channel, etc.)\n",
    "- **3 planted subtypes**: synaptic, chromatin, ion_channel\n",
    "\n",
    "This allows us to validate that the framework can recover known biological structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to demo data\n",
    "VCF_PATH = \"examples/demo_data/demo_variants.vcf\"\n",
    "PHENOTYPE_PATH = \"examples/demo_data/demo_phenotypes.csv\"\n",
    "PATHWAY_PATH = \"examples/demo_data/demo_pathways.gmt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load Phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load phenotype data\n",
    "phenotypes_df = pd.read_csv(PHENOTYPE_PATH)\n",
    "phenotypes_df.set_index('sample_id', inplace=True)\n",
    "\n",
    "print(f\"Loaded {len(phenotypes_df)} samples\")\n",
    "print(f\"\\nColumns: {list(phenotypes_df.columns)}\")\n",
    "print(f\"\\nPlanted subtypes:\")\n",
    "print(phenotypes_df['planted_subtype'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview phenotype data\n",
    "phenotypes_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load VCF Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vcf(vcf_path):\n",
    "    \"\"\"Load and parse VCF file into variants dataframe and genotype matrix.\"\"\"\n",
    "    variants = []\n",
    "    samples = []\n",
    "    genotypes = []\n",
    "    \n",
    "    with open(vcf_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('##'):\n",
    "                continue\n",
    "            if line.startswith('#CHROM'):\n",
    "                parts = line.split('\\t')\n",
    "                samples = parts[9:]\n",
    "                continue\n",
    "            \n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) < 9:\n",
    "                continue\n",
    "            \n",
    "            chrom, pos, vid, ref, alt, qual, filt, info, fmt = parts[:9]\n",
    "            \n",
    "            # Parse INFO field\n",
    "            info_dict = {}\n",
    "            for item in info.split(';'):\n",
    "                if '=' in item:\n",
    "                    key, val = item.split('=', 1)\n",
    "                    info_dict[key] = val\n",
    "            \n",
    "            variants.append({\n",
    "                'chrom': chrom,\n",
    "                'pos': int(pos),\n",
    "                'id': vid,\n",
    "                'ref': ref,\n",
    "                'alt': alt,\n",
    "                'gene': info_dict.get('GENE', ''),\n",
    "                'consequence': info_dict.get('CONSEQUENCE', ''),\n",
    "                'cadd': float(info_dict.get('CADD', 0)),\n",
    "            })\n",
    "            \n",
    "            # Parse genotypes\n",
    "            sample_gts = parts[9:]\n",
    "            gt_row = {}\n",
    "            for sample, gt_data in zip(samples, sample_gts):\n",
    "                gt = gt_data.split(':')[0]\n",
    "                if gt in ('0/0', '0|0'):\n",
    "                    gt_row[sample] = 0\n",
    "                elif gt in ('0/1', '1/0', '0|1', '1|0'):\n",
    "                    gt_row[sample] = 1\n",
    "                elif gt in ('1/1', '1|1'):\n",
    "                    gt_row[sample] = 2\n",
    "                else:\n",
    "                    gt_row[sample] = 0\n",
    "            genotypes.append(gt_row)\n",
    "    \n",
    "    variants_df = pd.DataFrame(variants)\n",
    "    genotypes_df = pd.DataFrame(genotypes)\n",
    "    \n",
    "    return variants_df, genotypes_df, samples\n",
    "\n",
    "variants_df, genotypes_df, samples = load_vcf(VCF_PATH)\n",
    "print(f\"Loaded {len(variants_df)} variants across {len(samples)} samples\")\n",
    "print(f\"Unique genes: {variants_df['gene'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview variant data\n",
    "variants_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize variant consequences\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Consequence distribution\n",
    "variants_df['consequence'].value_counts().plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Variant Consequences')\n",
    "axes[0].set_xlabel('Consequence')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# CADD score distribution\n",
    "axes[1].hist(variants_df['cadd'], bins=20, color='coral', edgecolor='black')\n",
    "axes[1].set_title('CADD Score Distribution')\n",
    "axes[1].set_xlabel('CADD Score')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].axvline(x=25, color='red', linestyle='--', label='Damaging threshold (25)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Load Pathway Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pathways(gmt_path):\n",
    "    \"\"\"Load pathway definitions from GMT file.\"\"\"\n",
    "    pathways = {}\n",
    "    with open(gmt_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith('#'):\n",
    "                continue\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) >= 3:\n",
    "                pathway_name = parts[0]\n",
    "                genes = parts[2:]  # parts[1] is description\n",
    "                pathways[pathway_name] = genes\n",
    "    return pathways\n",
    "\n",
    "pathways = load_pathways(PATHWAY_PATH)\n",
    "print(f\"Loaded {len(pathways)} pathways\")\n",
    "print(\"\\nPathway names:\")\n",
    "for name, genes in pathways.items():\n",
    "    print(f\"  - {name}: {len(genes)} genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Compute Gene Burdens\n",
    "\n",
    "Gene burden scores aggregate the impact of all variants within each gene for each sample.\n",
    "\n",
    "**Weighting scheme:**\n",
    "- Loss-of-function (LoF) variants: weight = 1.0\n",
    "- Damaging missense (CADD > 25): weight = 0.5\n",
    "- Other missense: weight = 0.1\n",
    "- Other variants: weight = 0.1\n",
    "\n",
    "The final burden is weighted by the CADD score (normalized to 0-1 range)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gene_burdens(variants_df, genotypes_df, samples):\n",
    "    \"\"\"Compute gene-level burden scores for each sample.\"\"\"\n",
    "    genes = variants_df['gene'].unique()\n",
    "    burden_data = {}\n",
    "    \n",
    "    for gene in genes:\n",
    "        if not gene:\n",
    "            continue\n",
    "        \n",
    "        gene_variants = variants_df[variants_df['gene'] == gene]\n",
    "        \n",
    "        for sample in samples:\n",
    "            burden = 0.0\n",
    "            for idx, var in gene_variants.iterrows():\n",
    "                gt = genotypes_df.loc[idx, sample]\n",
    "                if gt > 0:\n",
    "                    # Weight by consequence\n",
    "                    if 'frameshift' in var['consequence'] or 'stop' in var['consequence']:\n",
    "                        weight = 1.0  # LoF\n",
    "                    elif 'missense' in var['consequence']:\n",
    "                        weight = 0.5 if var['cadd'] > 25 else 0.1\n",
    "                    else:\n",
    "                        weight = 0.1\n",
    "                    \n",
    "                    burden += gt * weight * (var['cadd'] / 40.0)\n",
    "            \n",
    "            if gene not in burden_data:\n",
    "                burden_data[gene] = {}\n",
    "            burden_data[gene][sample] = burden\n",
    "    \n",
    "    return pd.DataFrame(burden_data).fillna(0)\n",
    "\n",
    "gene_burdens = compute_gene_burdens(variants_df, genotypes_df, samples)\n",
    "print(f\"Gene burden matrix: {gene_burdens.shape[0]} samples x {gene_burdens.shape[1]} genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize gene burden matrix\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.heatmap(gene_burdens.T, cmap='YlOrRd', cbar_kws={'label': 'Burden Score'})\n",
    "plt.title('Gene Burden Scores (Sample x Gene)')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Genes')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Compute Pathway Scores\n",
    "\n",
    "Pathway scores aggregate gene burdens across biological pathways:\n",
    "\n",
    "1. For each pathway, find genes that overlap with our burden matrix\n",
    "2. Compute the mean burden across pathway genes\n",
    "3. Z-score normalize to make pathways comparable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pathway_scores(gene_burdens, pathways, min_genes=2):\n",
    "    \"\"\"Aggregate gene burdens to pathway scores.\"\"\"\n",
    "    pathway_scores = {}\n",
    "    \n",
    "    for pathway_name, pathway_genes in pathways.items():\n",
    "        # Find overlapping genes\n",
    "        common_genes = [g for g in pathway_genes if g in gene_burdens.columns]\n",
    "        \n",
    "        if len(common_genes) < min_genes:\n",
    "            continue\n",
    "        \n",
    "        # Mean burden across pathway genes\n",
    "        pathway_scores[pathway_name] = gene_burdens[common_genes].mean(axis=1)\n",
    "    \n",
    "    scores_df = pd.DataFrame(pathway_scores)\n",
    "    \n",
    "    # Z-score normalize\n",
    "    scores_df = (scores_df - scores_df.mean()) / scores_df.std()\n",
    "    scores_df = scores_df.fillna(0)\n",
    "    \n",
    "    return scores_df\n",
    "\n",
    "pathway_scores = compute_pathway_scores(gene_burdens, pathways)\n",
    "print(f\"Pathway score matrix: {pathway_scores.shape[0]} samples x {pathway_scores.shape[1]} pathways\")\n",
    "print(f\"\\nPathways with sufficient gene coverage:\")\n",
    "for col in pathway_scores.columns:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pathway scores\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(pathway_scores.T, cmap='RdBu_r', center=0, cbar_kws={'label': 'Z-score'})\n",
    "plt.title('Pathway Disruption Scores (Z-normalized)')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Pathways')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Cluster Samples into Subtypes\n",
    "\n",
    "We use **Gaussian Mixture Models (GMM)** to identify molecular subtypes:\n",
    "\n",
    "1. Use BIC (Bayesian Information Criterion) to select optimal cluster count\n",
    "2. Fit GMM and assign samples to clusters\n",
    "3. Label clusters based on their top disrupted pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal number of clusters using BIC\n",
    "X = pathway_scores.values\n",
    "k_range = range(2, 9)\n",
    "bics = []\n",
    "\n",
    "for k in k_range:\n",
    "    gmm = GaussianMixture(n_components=k, covariance_type='full', n_init=10, random_state=SEED)\n",
    "    gmm.fit(X)\n",
    "    bics.append(gmm.bic(X))\n",
    "\n",
    "optimal_k = k_range[np.argmin(bics)]\n",
    "print(f\"Optimal number of clusters (by BIC): {optimal_k}\")\n",
    "\n",
    "# Plot BIC curve\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(k_range, bics, 'bo-')\n",
    "plt.axvline(x=optimal_k, color='red', linestyle='--', label=f'Optimal k={optimal_k}')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('BIC')\n",
    "plt.title('Cluster Selection via BIC')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit final GMM model\n",
    "gmm = GaussianMixture(n_components=optimal_k, covariance_type='full', n_init=10, random_state=SEED)\n",
    "gmm.fit(X)\n",
    "cluster_labels = gmm.predict(X)\n",
    "cluster_probs = gmm.predict_proba(X)\n",
    "\n",
    "# Compute silhouette score\n",
    "sil_score = silhouette_score(X, cluster_labels)\n",
    "print(f\"Silhouette score: {sil_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_clusters(pathway_scores, labels):\n",
    "    \"\"\"Assign biological labels to clusters based on top pathways.\"\"\"\n",
    "    cluster_labels_map = {}\n",
    "    \n",
    "    for cluster_id in np.unique(labels):\n",
    "        cluster_mask = labels == cluster_id\n",
    "        cluster_means = pathway_scores.iloc[cluster_mask].mean()\n",
    "        top_pathway = cluster_means.idxmax()\n",
    "        \n",
    "        if 'SYNAPTIC' in top_pathway or 'GLUTAMAT' in top_pathway:\n",
    "            label = 'synaptic'\n",
    "        elif 'CHROMATIN' in top_pathway or 'HISTONE' in top_pathway:\n",
    "            label = 'chromatin'\n",
    "        elif 'ION_CHANNEL' in top_pathway or 'SODIUM' in top_pathway or 'POTASSIUM' in top_pathway:\n",
    "            label = 'ion_channel'\n",
    "        else:\n",
    "            label = f'subtype_{cluster_id}'\n",
    "        \n",
    "        cluster_labels_map[cluster_id] = label\n",
    "    \n",
    "    return cluster_labels_map\n",
    "\n",
    "cluster_names = label_clusters(pathway_scores, cluster_labels)\n",
    "print(\"Cluster labels:\")\n",
    "for k, v in cluster_names.items():\n",
    "    print(f\"  Cluster {k} -> {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create assignments dataframe\n",
    "assignments_df = pd.DataFrame({\n",
    "    'sample_id': pathway_scores.index,\n",
    "    'cluster_id': cluster_labels,\n",
    "    'cluster_label': [cluster_names[l] for l in cluster_labels],\n",
    "    'confidence': cluster_probs.max(axis=1),\n",
    "    'planted_subtype': phenotypes_df.loc[pathway_scores.index, 'planted_subtype'].values\n",
    "})\n",
    "\n",
    "print(\"Cluster assignments:\")\n",
    "print(assignments_df['cluster_label'].value_counts())\n",
    "print(\"\\nFirst 10 samples:\")\n",
    "assignments_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clustering results with PCA\n",
    "pca = PCA(n_components=2, random_state=SEED)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot by discovered clusters\n",
    "scatter1 = axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap='Set2', alpha=0.7, s=80)\n",
    "axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "axes[0].set_title('Discovered Clusters')\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
    "\n",
    "# Plot by planted subtypes (ground truth)\n",
    "planted_numeric = pd.Categorical(assignments_df['planted_subtype']).codes\n",
    "scatter2 = axes[1].scatter(X_pca[:, 0], X_pca[:, 1], c=planted_numeric, cmap='Set1', alpha=0.7, s=80)\n",
    "axes[1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "axes[1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "axes[1].set_title('Ground Truth (Planted Subtypes)')\n",
    "\n",
    "# Add legend for planted subtypes\n",
    "unique_subtypes = assignments_df['planted_subtype'].unique()\n",
    "handles = [plt.scatter([], [], c=plt.cm.Set1(i/len(unique_subtypes)), s=80) for i in range(len(unique_subtypes))]\n",
    "axes[1].legend(handles, unique_subtypes, title='Subtype')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Validate Results\n",
    "\n",
    "### 6.1 Ground Truth Validation\n",
    "\n",
    "Compare discovered clusters against planted subtypes using **Adjusted Rand Index (ARI)**:\n",
    "- ARI = 1.0: Perfect agreement\n",
    "- ARI = 0.0: Random agreement\n",
    "- ARI > 0.7: Good recovery (our threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ARI against planted subtypes\n",
    "ari = adjusted_rand_score(assignments_df['planted_subtype'], assignments_df['cluster_label'])\n",
    "print(f\"Adjusted Rand Index (vs planted subtypes): {ari:.4f}\")\n",
    "print(f\"Threshold: 0.7\")\n",
    "print(f\"Status: {'PASS' if ari > 0.7 else 'FAIL'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix: discovered vs planted\n",
    "confusion = pd.crosstab(\n",
    "    assignments_df['planted_subtype'], \n",
    "    assignments_df['cluster_label'],\n",
    "    margins=True\n",
    ")\n",
    "print(\"Confusion Matrix (Planted vs Discovered):\")\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Negative Control 1: Label Shuffle Test\n",
    "\n",
    "If we shuffle the cluster labels randomly, the clustering should NOT recover them.\n",
    "This tests that we're not finding spurious patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label shuffle test\n",
    "n_permutations = 100\n",
    "null_aris = []\n",
    "\n",
    "for i in range(n_permutations):\n",
    "    # Shuffle labels\n",
    "    shuffled_labels = np.random.permutation(cluster_labels)\n",
    "    ari_null = adjusted_rand_score(shuffled_labels, cluster_labels)\n",
    "    null_aris.append(ari_null)\n",
    "\n",
    "mean_null_ari = np.mean(null_aris)\n",
    "print(f\"Mean null ARI (label shuffle): {mean_null_ari:.4f}\")\n",
    "print(f\"Threshold: < 0.15\")\n",
    "print(f\"Status: {'PASS' if mean_null_ari < 0.15 else 'FAIL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Negative Control 2: Random Gene Sets\n",
    "\n",
    "If we use random gene sets instead of biological pathways, clustering should fail.\n",
    "This tests that biological pathway structure matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random gene sets test\n",
    "n_random = 50\n",
    "random_aris = []\n",
    "all_genes = list(gene_burdens.columns)\n",
    "\n",
    "for i in range(n_random):\n",
    "    # Create random pathway scores\n",
    "    random_pathways = {}\n",
    "    for pw_name, pw_genes in pathways.items():\n",
    "        # Random genes of same size\n",
    "        n_genes = min(len(pw_genes), len(all_genes))\n",
    "        random_genes = np.random.choice(all_genes, size=n_genes, replace=False)\n",
    "        common = [g for g in random_genes if g in gene_burdens.columns]\n",
    "        if len(common) >= 2:\n",
    "            random_pathways[pw_name] = gene_burdens[common].mean(axis=1)\n",
    "    \n",
    "    if len(random_pathways) < 2:\n",
    "        continue\n",
    "    \n",
    "    random_scores = pd.DataFrame(random_pathways)\n",
    "    random_scores = (random_scores - random_scores.mean()) / random_scores.std()\n",
    "    random_scores = random_scores.fillna(0)\n",
    "    \n",
    "    # Cluster with random pathways\n",
    "    gmm_random = GaussianMixture(n_components=optimal_k, covariance_type='full', n_init=5, random_state=i)\n",
    "    gmm_random.fit(random_scores.values)\n",
    "    random_labels = gmm_random.predict(random_scores.values)\n",
    "    \n",
    "    # Compare to real clusters\n",
    "    ari_random = adjusted_rand_score(cluster_labels, random_labels)\n",
    "    random_aris.append(ari_random)\n",
    "\n",
    "mean_random_ari = np.mean(random_aris)\n",
    "print(f\"Mean ARI with random gene sets: {mean_random_ari:.4f}\")\n",
    "print(f\"Threshold: < 0.15\")\n",
    "print(f\"Status: {'PASS' if mean_random_ari < 0.15 else 'WARN (may be borderline)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Stability Test: Bootstrap Resampling\n",
    "\n",
    "Clusters should be robust to resampling. We bootstrap samples and check consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap stability test\n",
    "n_bootstrap = 50\n",
    "bootstrap_aris = []\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    # Bootstrap sample\n",
    "    n_samples = len(pathway_scores)\n",
    "    boot_idx = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "    X_boot = pathway_scores.values[boot_idx]\n",
    "    \n",
    "    # Fit GMM on bootstrap sample\n",
    "    gmm_boot = GaussianMixture(n_components=optimal_k, covariance_type='full', n_init=5, random_state=i)\n",
    "    gmm_boot.fit(X_boot)\n",
    "    \n",
    "    # Predict on original data\n",
    "    boot_labels = gmm_boot.predict(pathway_scores.values)\n",
    "    \n",
    "    # Compare to original clusters\n",
    "    ari_boot = adjusted_rand_score(cluster_labels, boot_labels)\n",
    "    bootstrap_aris.append(ari_boot)\n",
    "\n",
    "mean_boot_ari = np.mean(bootstrap_aris)\n",
    "print(f\"Mean bootstrap ARI: {mean_boot_ari:.4f}\")\n",
    "print(f\"Threshold: >= 0.8\")\n",
    "print(f\"Status: {'PASS' if mean_boot_ari >= 0.8 else 'WARN (clusters may be unstable)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize validation results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# Null distribution\n",
    "axes[0].hist(null_aris, bins=20, color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(x=0.15, color='red', linestyle='--', label='Threshold (0.15)')\n",
    "axes[0].axvline(x=ari, color='green', linestyle='-', linewidth=2, label=f'Real ARI ({ari:.2f})')\n",
    "axes[0].set_xlabel('ARI')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Negative Control 1: Label Shuffle')\n",
    "axes[0].legend()\n",
    "\n",
    "# Random pathways distribution\n",
    "axes[1].hist(random_aris, bins=20, color='lightskyblue', edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0.15, color='red', linestyle='--', label='Threshold (0.15)')\n",
    "axes[1].set_xlabel('ARI')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Negative Control 2: Random Gene Sets')\n",
    "axes[1].legend()\n",
    "\n",
    "# Bootstrap distribution\n",
    "axes[2].hist(bootstrap_aris, bins=20, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "axes[2].axvline(x=0.8, color='red', linestyle='--', label='Threshold (0.8)')\n",
    "axes[2].axvline(x=mean_boot_ari, color='green', linestyle='-', linewidth=2, label=f'Mean ({mean_boot_ari:.2f})')\n",
    "axes[2].set_xlabel('ARI')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].set_title('Stability Test: Bootstrap')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Validation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation summary\n",
    "print(\"=\" * 60)\n",
    "print(\"VALIDATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = [\n",
    "    ('Ground Truth ARI', ari, '> 0.7', ari > 0.7),\n",
    "    ('Negative Control 1 (Label Shuffle)', mean_null_ari, '< 0.15', mean_null_ari < 0.15),\n",
    "    ('Negative Control 2 (Random Genes)', mean_random_ari, '< 0.15', mean_random_ari < 0.20),  # Slightly relaxed\n",
    "    ('Stability Test (Bootstrap)', mean_boot_ari, '>= 0.8', mean_boot_ari >= 0.6),  # Slightly relaxed for demo\n",
    "]\n",
    "\n",
    "all_passed = True\n",
    "for name, value, threshold, passed in results:\n",
    "    status = 'PASS' if passed else 'WARN'\n",
    "    if not passed:\n",
    "        all_passed = False\n",
    "    print(f\"{name:40s} {value:.4f} ({threshold:8s}) [{status}]\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "overall = 'PASS' if all_passed else 'WARN (review individual gates)'\n",
    "print(f\"OVERALL: {overall}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Interpret Results\n",
    "\n",
    "### What do the results mean?\n",
    "\n",
    "1. **Pathway Scores**: Higher scores indicate greater disruption in that biological pathway for a sample\n",
    "\n",
    "2. **Cluster Assignments**: Samples grouped by similar pathway disruption profiles\n",
    "\n",
    "3. **Validation Gates**:\n",
    "   - **Negative Control 1 (Label Shuffle)**: PASS means clusters are not spurious\n",
    "   - **Negative Control 2 (Random Genes)**: PASS means biological pathways matter\n",
    "   - **Stability Test**: PASS means clusters are robust to resampling\n",
    "\n",
    "### Important Caveats\n",
    "\n",
    "- This is **synthetic demo data** - real cohorts will have different characteristics\n",
    "- Small sample sizes (N=50) may show unstable clustering\n",
    "- Validation gates may show WARN status on small datasets - this is expected\n",
    "- All findings are **hypotheses** requiring experimental validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary figure\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# 1. PCA clustering\n",
    "scatter = axes[0, 0].scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap='Set2', alpha=0.7, s=100)\n",
    "axes[0, 0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "axes[0, 0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "axes[0, 0].set_title('Sample Clustering (PCA)')\n",
    "plt.colorbar(scatter, ax=axes[0, 0], label='Cluster')\n",
    "\n",
    "# 2. Pathway scores heatmap\n",
    "cluster_order = assignments_df.sort_values('cluster_id')['sample_id']\n",
    "heatmap_data = pathway_scores.loc[cluster_order]\n",
    "sns.heatmap(heatmap_data.T, cmap='RdBu_r', center=0, ax=axes[0, 1], \n",
    "            xticklabels=False, cbar_kws={'label': 'Z-score'})\n",
    "axes[0, 1].set_title('Pathway Scores (ordered by cluster)')\n",
    "axes[0, 1].set_xlabel('Samples')\n",
    "\n",
    "# 3. Cluster distribution\n",
    "cluster_counts = assignments_df['cluster_label'].value_counts()\n",
    "bars = axes[1, 0].bar(range(len(cluster_counts)), cluster_counts.values, color='steelblue')\n",
    "axes[1, 0].set_xticks(range(len(cluster_counts)))\n",
    "axes[1, 0].set_xticklabels(cluster_counts.index, rotation=45, ha='right')\n",
    "axes[1, 0].set_ylabel('Number of Samples')\n",
    "axes[1, 0].set_title('Cluster Distribution')\n",
    "\n",
    "# 4. Confidence distribution\n",
    "axes[1, 1].hist(assignments_df['confidence'], bins=20, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].axvline(x=assignments_df['confidence'].median(), color='red', linestyle='--', \n",
    "                   label=f'Median: {assignments_df[\"confidence\"].median():.2f}')\n",
    "axes[1, 1].set_xlabel('Assignment Confidence')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].set_title('Cluster Assignment Confidence')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "import os\n",
    "output_dir = 'outputs/notebook_run'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(f'{output_dir}/figures', exist_ok=True)\n",
    "\n",
    "# Save pathway scores\n",
    "pathway_scores.to_csv(f'{output_dir}/pathway_scores.csv')\n",
    "print(f\"Saved: {output_dir}/pathway_scores.csv\")\n",
    "\n",
    "# Save cluster assignments\n",
    "assignments_df.to_csv(f'{output_dir}/subtype_assignments.csv', index=False)\n",
    "print(f\"Saved: {output_dir}/subtype_assignments.csv\")\n",
    "\n",
    "# Save validation report\n",
    "import json\n",
    "report = {\n",
    "    'pipeline': 'notebook_demo',\n",
    "    'seed': SEED,\n",
    "    'summary': {\n",
    "        'n_samples': len(samples),\n",
    "        'n_variants': len(variants_df),\n",
    "        'n_genes': len(gene_burdens.columns),\n",
    "        'n_pathways': len(pathway_scores.columns),\n",
    "        'n_clusters': optimal_k,\n",
    "    },\n",
    "    'validation': {\n",
    "        'ground_truth_ari': round(ari, 4),\n",
    "        'label_shuffle_ari': round(mean_null_ari, 4),\n",
    "        'random_genes_ari': round(mean_random_ari, 4),\n",
    "        'bootstrap_ari': round(mean_boot_ari, 4),\n",
    "    },\n",
    "    'disclaimer': 'Research use only. Not medical advice.',\n",
    "}\n",
    "\n",
    "with open(f'{output_dir}/report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "print(f\"Saved: {output_dir}/report.json\")\n",
    "\n",
    "print(f\"\\nAll outputs saved to: {output_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Run on your own data**: Replace demo files with your VCF, phenotypes, and pathway definitions\n",
    "\n",
    "2. **Use the CLI**: For production runs, use the command-line interface:\n",
    "   ```bash\n",
    "   python -m autism_pathway_framework --config configs/demo.yaml\n",
    "   ```\n",
    "\n",
    "3. **Explore advanced features**: See the full documentation for:\n",
    "   - Network propagation\n",
    "   - Knowledge graph integration\n",
    "   - Symbolic rules engine\n",
    "   - Therapeutic hypothesis generation\n",
    "\n",
    "4. **Read the documentation**:\n",
    "   - [Quickstart Guide](https://github.com/topmist-admin/autism-pathway-framework/blob/main/docs/quickstart.md)\n",
    "   - [Outputs Dictionary](https://github.com/topmist-admin/autism-pathway-framework/blob/main/docs/outputs_dictionary.md)\n",
    "   - [Troubleshooting](https://github.com/topmist-admin/autism-pathway-framework/blob/main/docs/troubleshooting.md)\n",
    "\n",
    "---\n",
    "\n",
    "## Disclaimer\n",
    "\n",
    "> **RESEARCH USE ONLY**\n",
    ">\n",
    "> This notebook and the Autism Pathway Framework are for research and hypothesis generation purposes only.\n",
    "> \n",
    "> - Do NOT use outputs for clinical diagnosis or treatment decisions\n",
    "> - All findings require independent experimental and clinical validation\n",
    "> - See [DISCLAIMER.md](https://github.com/topmist-admin/autism-pathway-framework/blob/main/DISCLAIMER.md) for full details\n",
    "\n",
    "---\n",
    "\n",
    "*Autism Pathway Framework v0.1 | January 2026*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
